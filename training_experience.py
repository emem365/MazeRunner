import numpy as np
from constants import *


class Experience(object):
  def __init__(self, model, max_memory = 100, discount = 0.95):
    self.model = model
    self.max_memory = max_memory
    self.discount = discount
    self.memory = list()
    self.num_actions = model.output_shape[-1]
  
  def remember(self, episode):
    self.memory.append(episode)
    if(len(self.memory)>self.max_memory):
      self.memory.pop(0)

  def predict(self, envstate):
    return self.model.predict(envstate)[0]
  
  def get_data(self, data_size = 10):
    env_size = self.memory[0][0].shape[1]
    mem_size = len(self.memory)
    data_size = min(mem_size, data_size)

    inputs = np.zeros((data_size, env_size))
    targets = np.zeros((data_size, self.num_actions))

    for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):
      envstate, action, reward, envstate_next, game_over = self.memory[j]
      inputs[i] = envstate
      targets[i] = self.predict(envstate)
      Q_sa = np.max(self.predict(envstate_next))
      if game_over:
        targets[i, action] = reward
      else:
        targets[i, action] = reward + self.discount * Q_sa
    return inputs, targets
